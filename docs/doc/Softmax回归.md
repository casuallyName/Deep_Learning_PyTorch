<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
# Softmax回归
当输出为离散值时，线性回归是无法使用的。对于这样的离散值预测问题，需要引入诸如softmax回归在内的分类模型。softmax模型的输出单元从一个变成多个，且引入了softmax运算使输出更适合离散值的预测和训练
下面介绍一个简单的图像分类问题，且输入图像宽和高均为2像素，且色彩为灰度。这样每个像素值都可以用一个标量表示。将图像中的4个像素点分别标记为$x_1,x_2,x_3,x_4$。现假设舒蕾数据集中的图像真实标签为「猫」「狗」（为简化问题，假设猫、狗图像可在4个像素内表示），这些标签分别对应离散值$y_1,y_2$。
在图像分类问题中，通常使用离散值来表达分类，如$y_1=1,y_2=2$。即标签1映射类为猫，标签2映射类为狗。虽然仍然可以使用线性回归模型来进行建模，将输出结果近似到两个离散值中的一个，但这样做存在较大的误差，回影响到分类质量。
## softmax回归模型
Softmax回归跟线性回归一样将输入特征与权重做线性叠加，但softmax回归的输出值个数等于标签类别数。对于上述模型，一共有4种输入特征($x_1,x_2,x_3,x_4$)和2种输出类别($o_1,o_2$)，包含8个权重标量($w_i$)和2个偏差标量($b_i$)，其表达式为：
$$o_1=x_1 w_{11}+x_2 w_{21}+x_3 w_{31}+x_4 w_{41}+b_1\\
o_2=x_1 w_{12}+x_2 w_{22}+x_3 w_{32}+x_4 w_{42}+b_2$$
Softmax回归同线性回归一样，也是一个单层神经网络。由于每个输出$o_1,o_2$的计算都要依赖于所有的输入$x_1,x_2,x_3,x_4$，因此softmax回归的输出层也是一个全连接层。

![](img/softmax_1.png)

## softmax运算
既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值$o_i$当作预测类别是i的置信度，并将值最大的输出所对应的类作为预测输出，即输出$argmax(o_i)$。例如，某次输入结果$o_1=10,o_2=0.1$，由于o_1最大，那么预测类别为0，映射类为猫。
然而，直接使用输出层的输出有两个问题。
	由于输出层的输出值的范围不确定，难以直观上判断这些值的意义。如，$o_1$输出值10只能表示图像为猫的可能很大，因为该输出值是$o_2$输出值的100倍。但如果此时$o_2$输出值为1000时，$o_1$输出值10又表示图像为猫的可能很小。
	由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。
Softmax运算符（softmax operator）用来解决了以上两个问题。它通过下式将输出值变换成值为正且和为1的概率分布：
$$\hat{y}=\frac{e^{o_i }}{∑_{i=1}^n e^{o_i}}$$
不难看出，$∑_{i=1}^n \hat{y_i} =1，0≤\hat{y_i}≤1$。因此$\hat{y_i}$是一个合法的概率分布。且${{argmax}_i}{o_i}={{argmax}_i}{\hat{y_i}}$，因此softmax运算不改变预测类别输出。
此时对于上述的分类问题有：
$$\hat{y_1},\hat{y_2}={softmax}({o_1},{o_2})$$
如果$\hat{y_1}=0.8$，即可认为图像类别为猫的概率是80%。
##交叉熵损失函数

